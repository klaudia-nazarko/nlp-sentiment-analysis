{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with n-grams and GridSearch\n",
    "\n",
    "When looking for ways how to improve performance of sentiment analysis model, it's good to reach for such ideas as:\n",
    "- optimising text representations,\n",
    "- hyperparameters tuning.\n",
    "\n",
    "In the first part, let's confront the performance of initial word vectors by testing word vectors containing not only unigrams but also n-grams of size 2 and 3 (with and without stop words removal).\n",
    "\n",
    "In the second part, the GridSearchCV tool will be used to find the most optimal setup of model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/reviews_toys_games_100k.csv')\n",
    "\n",
    "reviews = df['review'].astype('U').values\n",
    "y = df['sentiment'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part contains the comparison of 6 different combinations of BOW and TF-IDF models, with n-grams of size 2 and 3, with and without stop words removal.\n",
    "\n",
    "Obtained results are very similar in each variant, however the best performance was achieved with BOW model with uni- and bi-grams, without stop words removal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_bow_1 = CountVectorizer(stop_words='english', ngram_range=(1,2), max_features=6000).fit_transform(reviews)\n",
    "M_bow_2 = CountVectorizer(ngram_range=(1,2), max_features=6000).fit_transform(reviews)\n",
    "M_bow_3 = CountVectorizer(ngram_range=(1,3), max_features=6000).fit_transform(reviews)\n",
    "\n",
    "M_tfidf_1 = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=6000).fit_transform(reviews)\n",
    "M_tfidf_2 = TfidfVectorizer(ngram_range=(1,2), max_features=6000).fit_transform(reviews)\n",
    "M_tfidf_3 = TfidfVectorizer(ngram_range=(1,3), max_features=6000).fit_transform(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_names = ['M_bow_1', 'M_bow_2', 'M_bow_3', 'M_tfidf_1', 'M_tfidf_2', 'M_tfidf_3']\n",
    "embeddings = [M_bow_1, M_bow_2, M_bow_3, M_tfidf_1, M_tfidf_2, M_tfidf_3]\n",
    "results_names = ['test_acc', 'f1', 'precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M_bow_1</th>\n",
       "      <td>0.95922</td>\n",
       "      <td>0.977965</td>\n",
       "      <td>0.966973</td>\n",
       "      <td>0.989211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_bow_2</th>\n",
       "      <td>0.96663</td>\n",
       "      <td>0.981860</td>\n",
       "      <td>0.976483</td>\n",
       "      <td>0.987309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_bow_3</th>\n",
       "      <td>0.96599</td>\n",
       "      <td>0.981502</td>\n",
       "      <td>0.976743</td>\n",
       "      <td>0.986314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_tfidf_1</th>\n",
       "      <td>0.95067</td>\n",
       "      <td>0.973677</td>\n",
       "      <td>0.951147</td>\n",
       "      <td>0.997300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_tfidf_2</th>\n",
       "      <td>0.95853</td>\n",
       "      <td>0.977777</td>\n",
       "      <td>0.959045</td>\n",
       "      <td>0.997256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_tfidf_3</th>\n",
       "      <td>0.95816</td>\n",
       "      <td>0.977580</td>\n",
       "      <td>0.958817</td>\n",
       "      <td>0.997092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           test_acc        f1  precision    recall\n",
       "M_bow_1     0.95922  0.977965   0.966973  0.989211\n",
       "M_bow_2     0.96663  0.981860   0.976483  0.987309\n",
       "M_bow_3     0.96599  0.981502   0.976743  0.986314\n",
       "M_tfidf_1   0.95067  0.973677   0.951147  0.997300\n",
       "M_tfidf_2   0.95853  0.977777   0.959045  0.997256\n",
       "M_tfidf_3   0.95816  0.977580   0.958817  0.997092"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier(random_state=9, n_jobs=-1)\n",
    "\n",
    "sgd_cv = f.model_cv(sgd, embeddings, y)\n",
    "f.df_model_cv(sgd_cv, embeddings_names, results_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Cross Validations\n",
    "\n",
    "GridSearchCV evaluates all hyper-parameters' combinations and indicates the configuration with the highest score. This script will focus on finding the optimal setting of parameters: loss, penalty, alpha and max_iter.\n",
    "The conclusion is that the best configuration of the model is the default one, although it's enough to use 800 iterations instead of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SGDClassifier(n_jobs=-1, random_state=9),\n",
       "             param_grid={'alpha': (0.0001, 0.0005), 'loss': ('hinge', 'log'),\n",
       "                         'max_iter': [800, 1000, 1200],\n",
       "                         'penalty': ('l1', 'l2')})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'loss': ('hinge', 'log'),\n",
    "    'penalty': ('l1', 'l2'),\n",
    "    'alpha':(0.0001, 0.0005), \n",
    "    'max_iter':[800, 1000, 1200]}\n",
    "\n",
    "sgd = SGDClassifier(random_state=9, n_jobs=-1)\n",
    "clf = GridSearchCV(sgd, parameters)\n",
    "clf.fit(M_bow_2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.0001, 'loss': 'hinge', 'max_iter': 800, 'penalty': 'l2'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>M_bow_2</th>\n",
       "      <td>0.96663</td>\n",
       "      <td>0.98186</td>\n",
       "      <td>0.976483</td>\n",
       "      <td>0.987309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         test_acc       f1  precision    recall\n",
       "M_bow_2   0.96663  0.98186   0.976483  0.987309"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_best_params = SGDClassifier(max_iter=800, random_state=9, n_jobs=-1)\n",
    "sgd_best_cv = f.model_cv(sgd, [M_bow_2], y)\n",
    "f.df_model_cv(sgd_best_cv, ['M_bow_2'], results_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-nlp",
   "language": "python",
   "name": "fastai-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
