{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klaud\\Anaconda3\\envs\\fastai-nlp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word -> text -> text_corpus\n",
    "token -> text_token -> tokens_corpus\n",
    "ind -> text_ind -> ind_corpus\n",
    "corpus_counter\n",
    "\n",
    "text: string ze słowami -> word\n",
    "\n",
    "text_token: lista z tokenami -> token\n",
    "\n",
    "text_ind: lista z indexami tokenów -> ind\n",
    "\n",
    "text_corpus: lista stringów ze słowami\n",
    "\n",
    "tokens_corpus: lista list z tokenami\n",
    "\n",
    "corpus_counter: słownik ze słowami i częstotliwościami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text preprocessing\n",
    "\n",
    "Creating word tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>81660</th>\n",
       "      <td>Awesome snowball maker! A must-have for snow p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822458</th>\n",
       "      <td>Perfect for a child and free on-line lessons w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543013</th>\n",
       "      <td>I love this product because my granddaughter l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925083</th>\n",
       "      <td>ok for the money</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019005</th>\n",
       "      <td>In a crowded field of electronic talking toys,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review  sentiment\n",
       "81660    Awesome snowball maker! A must-have for snow p...          1\n",
       "822458   Perfect for a child and free on-line lessons w...          1\n",
       "543013   I love this product because my granddaughter l...          1\n",
       "925083                                    ok for the money          1\n",
       "1019005  In a crowded field of electronic talking toys,...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/reviews_toys_games.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.914674872933972"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['sentiment'])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9148"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df.sample(100000, random_state=11).reset_index(drop=True)\n",
    "sum(df_sample['sentiment'])/len(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df_sample['review'].to_list()\n",
    "sentiment = df_sample['sentiment'].to_list()\n",
    "\n",
    "#reviews = df['review'][:10000].to_list()\n",
    "#sentiment = df['sentiment'][:10000].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokens = f.normalize_text(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in the dictionary:  45629\n",
      "Most common words:  [('love', 42733), ('great', 26982), ('play', 20313), ('toy', 16773), ('old', 16037), ('like', 15440), ('buy', 14097), ('kid', 13786), ('game', 13429), ('fun', 13182)]\n"
     ]
    }
   ],
   "source": [
    "corpus_counter, n_tokens = f.distinct_corpus_words(reviews_tokens)\n",
    "\n",
    "print('Words in the dictionary: ', n_tokens)\n",
    "print('Most common words: ', corpus_counter[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('data/reviews_tokens_10k.pickle', 'wb') as handle:\n",
    "#    pickle.dump(reviews_tokens, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "#with open('data/sentiment_10k.pickle', 'wb') as handle:\n",
    "#    pickle.dump(sentiment, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sample.to_csv('data/reviews_toys_games_100k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "reviews = None\n",
    "reviews_tokens = None\n",
    "sentiment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/reviews_tokens_10k.pickle', 'rb') as handle:\n",
    "    reviews_tokens = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_counter, n_tokens = f.distinct_corpus_words(reviews_tokens)\n",
    "word2ind, ind2word = f.build_dictionary(corpus_counter)\n",
    "reviews_ind = [f.text_token2ind(review, word2ind) for review in reviews_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/reviews_ind_100k.pickle', 'wb') as handle:\n",
    "    pickle.dump(reviews_ind, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_bow = f.build_bow(reviews_ind, n_tokens, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6000)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text of test review:  ['great', 'figure', 'right', 'price', 'love', 'amaze', 'figure', 'see']\n",
      "occurrences of words: \n",
      "figure: 2 \n",
      "love: 1\n"
     ]
    }
   ],
   "source": [
    "ind_test = 111\n",
    "print('text of test review: ', reviews_tokens[ind_test])\n",
    "print('occurrences of words:',\n",
    "      '\\nfigure:', S_bow.todense()[ind_test, word2ind['figure']],\n",
    "      '\\nlove:', S_bow.todense()[ind_test, word2ind['love']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/M_bow_10k.pickle', 'wb') as handle:\n",
    "    pickle.dump(S_bow, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "S_bow = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert string to BOW vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_test = 'This game is amazing ^^, my son plays with it all the time! popolsku behavoir'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['game', 'amaze', 'son', 'play', 'time', 'popolsku', 'behavoir']\n",
      "[8, 171, 20, 2, 18]\n"
     ]
    }
   ],
   "source": [
    "review_tokens_test = f.normalize_single_text(review_test)\n",
    "print(review_tokens_test)\n",
    "\n",
    "review_ind_test = f.text_token2ind(review_tokens_test, word2ind)\n",
    "print(review_ind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.build_single_bow(review_ind_test, n_tokens, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=6000)\n",
    "M_tfidf = vectorizer.fit_transform([' '.join(r) for r in reviews_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text of test review:  ['great', 'figure', 'right', 'price', 'love', 'amaze', 'figure', 'see']\n",
      "TFIDF of words: \n",
      "figure: 0.6571834159729407 \n",
      "love: 0.15079671030826042\n"
     ]
    }
   ],
   "source": [
    "ind_test = 111\n",
    "print('text of test review: ', reviews_tokens[ind_test])\n",
    "print('TFIDF of words:',\n",
    "      '\\nfigure:', M_tfidf.todense()[ind_test, vectorizer.vocabulary_['figure']],\n",
    "      '\\nlove:', M_tfidf.todense()[ind_test, vectorizer.vocabulary_['love']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/M_tfidf_10kx.pickle', 'wb') as handle:\n",
    "    pickle.dump(M_tfidf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('data/tfidf_vectorizer_10kx.pickle', 'wb') as handle:\n",
    "    pickle.dump(vectorizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "M_tfidf = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert test string into TFIDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x45595 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([' '.join(review_tokens_test)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD & NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_co_occurrence = f.build_co_occurrence_matrix(reviews_ind, n_tokens, window_size=4)\n",
    "svd_reduced_co_occurrence = f.matrix_reduce(S_co_occurrence, method='svd', n_dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_svd = np.stack([f.avg_svd_embeddings(ind, svd_reduced_co_occurrence, word2ind) for ind in reviews_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1911.32207339,  -42.3008621 , -106.35712762,  210.05471684,\n",
       "        -132.18560821],\n",
       "       [3295.92654462,  -56.23929451, -170.39622825,  528.90670812,\n",
       "        -241.31622704],\n",
       "       [6867.38013304,  903.19521856, -400.92224674,  805.06355755,\n",
       "        -199.5148494 ],\n",
       "       ...,\n",
       "       [3972.9144837 ,   30.86035388, -292.65034272,  950.86000508,\n",
       "        -256.2331357 ],\n",
       "       [1786.67156989, -840.48356118,    8.95530309,  -40.0365764 ,\n",
       "        -613.58495123],\n",
       "       [1798.51858078, -323.86781434,   12.39257531, -192.91452964,\n",
       "         260.19561892]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/M_svd_10k.pickle', 'wb') as handle:\n",
    "    pickle.dump(M_svd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "M_svd = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klaud\\Anaconda3\\envs\\fastai-nlp\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "nmf_reduced_co_occurrence = f.matrix_reduce(S_co_occurrence, method='nmf', n_dim=5)\n",
    "M_nmf = np.stack([f.avg_svd_embeddings(ind, nmf_reduced_co_occurrence, word2ind) for ind in reviews_ind])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.60028164,  2.57640671,  2.69019925,  7.05719044,  2.88720161],\n",
       "       [ 9.33532712,  3.50661315,  4.50025913, 13.47148637,  4.54616834],\n",
       "       [12.98326499, 12.95530018, 15.3185457 , 29.26370138,  8.88202786],\n",
       "       ...,\n",
       "       [ 9.86596451,  3.95031209,  4.99392973, 18.75379105,  5.03843315],\n",
       "       [12.51094802,  0.09438544,  0.11250818,  2.27895359,  1.28957891],\n",
       "       [ 4.79368268,  2.69853506,  2.86355823,  2.46593873,  8.70588732]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_nmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_nmf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/M_nmf_10k.pickle', 'wb') as handle:\n",
    "    pickle.dump(M_nmf, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "M_nmf = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert test string into SVD vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4686.7329675 , -783.00008166,   60.1869311 , -652.26470709,\n",
       "       1337.28247198])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.avg_svd_embeddings(review_ind_test, svd_reduced_co_occurrence, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=5,\n",
    "                     window=3,\n",
    "                     size=100,\n",
    "                     workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.build_vocab(reviews_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42808281, 50905110)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(reviews_tokens, total_examples=w2v_model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_word2vec = np.stack([f.avg_w2v_embeddings(review, w2v_model) for review in reviews_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_word2vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/M_word2vec_10k.pickle', 'wb') as handle:\n",
    "    pickle.dump(M_word2vec, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "M_word2vec = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert test string into Word2Vec vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.5881122 , -0.09375161,  0.3112844 , -0.6094233 , -0.01624112,\n",
       "       -0.35252064, -0.04945514,  1.472853  , -0.610626  ,  0.60974365,\n",
       "        0.19933842, -0.34043843,  0.1133698 , -0.508508  , -0.4323098 ,\n",
       "        0.30448467, -0.32596973, -0.9389588 , -0.37004104, -0.22721644,\n",
       "       -0.62874615,  0.26884118, -0.42678374, -0.85855293, -0.06089675,\n",
       "       -0.21786563, -0.06300454, -0.5797468 ,  0.25479466, -0.62527835,\n",
       "       -0.35483462,  0.45905322,  0.30274215,  1.3049182 ,  1.3136592 ,\n",
       "       -0.3332328 , -0.89768445, -0.8766676 , -0.16467395,  0.21572284,\n",
       "       -0.3336801 , -0.67071676,  0.31391215, -1.3378918 , -0.45184407,\n",
       "       -0.00443459,  1.0300862 ,  0.01396239, -0.23985538,  0.14696845,\n",
       "        1.2677801 ,  0.0497361 , -0.91047704, -0.41100398,  0.54817307,\n",
       "       -0.09938812,  0.20715058,  0.1469661 ,  0.32946473,  0.35771504,\n",
       "       -0.14450638, -1.1337442 ,  0.5253822 , -0.81195945, -0.79146224,\n",
       "        0.12864593,  0.13642989, -0.75450695, -0.14526239, -0.26831466,\n",
       "        0.73349106,  0.14306581, -0.33731437,  0.00954931,  0.15633671,\n",
       "       -0.0495903 ,  0.11877307,  0.3741429 ,  1.0396696 ,  0.5173938 ,\n",
       "        0.8256176 ,  0.75810957, -1.0848792 , -0.05949217, -0.71980375,\n",
       "        0.2332871 , -0.6340183 , -0.11127234,  0.24712288, -0.65251875,\n",
       "       -0.12997372,  0.29384452, -0.3969237 , -0.15692402,  0.34337506,\n",
       "       -0.25105777,  0.63227475,  0.39998084,  0.29872268, -0.26469955],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.avg_w2v_embeddings(review_tokens_test, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-nlp",
   "language": "python",
   "name": "fastai-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
