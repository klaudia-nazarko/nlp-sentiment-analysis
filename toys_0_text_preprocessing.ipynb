{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Word Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klaud\\Anaconda3\\envs\\fastai-nlp\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import functions as f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing\n",
    "\n",
    "The goal of this part is to transform product reviews into lists of tokens. Since the dataset consists of over 1.4M reviews, for the purpose of this project it will be limited to 100k (to fasten computations).\n",
    "\n",
    "Text preprocessing includes:\n",
    "- converting text to lowercase\n",
    "- removing punctuation\n",
    "- tokenization\n",
    "- removing stop words\n",
    "- lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1171865</th>\n",
       "      <td>Very nice toy!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230362</th>\n",
       "      <td>We gave this to our then, 14 month old dd and ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120094</th>\n",
       "      <td>The stuffed horse I recieved looks nothing lik...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893200</th>\n",
       "      <td>My grandson loves the Star Wars lego sets.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160189</th>\n",
       "      <td>I like this line of Teenys. Hadn't seen this o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review  sentiment\n",
       "1171865                                     Very nice toy!          1\n",
       "230362   We gave this to our then, 14 month old dd and ...          1\n",
       "120094   The stuffed horse I recieved looks nothing lik...          0\n",
       "893200          My grandson loves the Star Wars lego sets.          1\n",
       "1160189  I like this line of Teenys. Hadn't seen this o...          1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/reviews_toys_games.csv')\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of positive reviews in the whole dataset: 0.914674872933972\n"
     ]
    }
   ],
   "source": [
    "print('Share of positive reviews in the whole dataset:', sum(df['sentiment'])/len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of positive reviews in the sample: 0.9148\n"
     ]
    }
   ],
   "source": [
    "df_sample = df.sample(100000, random_state=11).reset_index(drop=True)\n",
    "print('Share of positive reviews in the sample:', sum(df_sample['sentiment'])/len(df_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = df_sample['review'].to_list()\n",
    "sentiment = df_sample['sentiment'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokens = f.normalize_text(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_pickle(reviews_tokens, 'data/reviews_tokens_100k.pickle')\n",
    "f.save_pickle(sentiment, 'data/sentiment_100k.pickle')\n",
    "\n",
    "df_sample.to_csv('data/reviews_toys_games_100k.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df, df_sample, reviews, reviews_tokens, sentiment, corpus_counter, n_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating word vectors\n",
    "\n",
    "There are several approaches aimed on transforming text into word vectors. In this script reviews will be presented as:\n",
    "- bag of words vectors\n",
    "- TFIDF word vectors\n",
    "- SVD and NMF embeddings\n",
    "- Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_tokens = f.load_pickle('data/reviews_tokens_100k.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_counter, n_tokens = f.distinct_corpus_words(reviews_tokens)\n",
    "word2ind, ind2word = f.build_dictionary(corpus_counter)\n",
    "reviews_ind = [f.text_token2ind(review, word2ind) for review in reviews_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in the dictionary:  45629\n",
      "Most common words:\n",
      " [('love', 42733), ('great', 26982), ('play', 20313), ('toy', 16773), ('old', 16037), ('like', 15440), ('buy', 14097), ('kid', 13786), ('game', 13429), ('fun', 13182)]\n"
     ]
    }
   ],
   "source": [
    "print('Words in the dictionary: ', n_tokens)\n",
    "print('Most common words:\\n', corpus_counter[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_pickle(reviews_ind, 'data/reviews_ind_100k.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6000)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_bow = f.build_bow(reviews_ind, n_tokens, 6000)\n",
    "M_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text of test review:  ['great', 'figure', 'right', 'price', 'love', 'amaze', 'figure', 'see']\n",
      "occurrences of words: \n",
      "figure: 2 \n",
      "love: 1\n"
     ]
    }
   ],
   "source": [
    "ind_test = 111\n",
    "print('text of test review: ', reviews_tokens[ind_test])\n",
    "print('occurrences of words:',\n",
    "      '\\nfigure:', M_bow[ind_test, word2ind['figure']],\n",
    "      '\\nlove:', M_bow[ind_test, word2ind['love']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_pickle(M_bow, 'data/M_bow_100k.pickle')\n",
    "del M_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert string to BOW vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_test = 'This game is amazing ^^, my son plays with it all the time!'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['game', 'amaze', 'son', 'play', 'time']\n",
      "[8, 171, 20, 2, 18]\n"
     ]
    }
   ],
   "source": [
    "review_tokens_test = f.normalize_single_text(review_test)\n",
    "print(review_tokens_test)\n",
    "\n",
    "review_ind_test = f.text_token2ind(review_tokens_test, word2ind)\n",
    "print(review_ind_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.build_single_bow(review_ind_test, n_tokens, 6000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 6000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=6000)\n",
    "M_tfidf = vectorizer.fit_transform([' '.join(r) for r in reviews_tokens])\n",
    "M_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text of test review:  ['great', 'figure', 'right', 'price', 'love', 'amaze', 'figure', 'see']\n",
      "TFIDF of words: \n",
      "figure: 0.6571834159729407 \n",
      "love: 0.15079671030826042\n"
     ]
    }
   ],
   "source": [
    "ind_test = 111\n",
    "print('text of test review: ', reviews_tokens[ind_test])\n",
    "print('TFIDF of words:',\n",
    "      '\\nfigure:', M_tfidf[ind_test, vectorizer.vocabulary_['figure']],\n",
    "      '\\nlove:', M_tfidf[ind_test, vectorizer.vocabulary_['love']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_pickle(M_tfidf, 'data/M_tfidf_100k.pickle')\n",
    "f.save_pickle(vectorizer, 'data/tfidf_vectorizer_100k.pickle')\n",
    "\n",
    "del M_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert test string into TFIDF vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([' '.join(review_tokens_test)]).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD & NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_co_occurrence = f.build_co_occurrence_matrix(reviews_ind, n_tokens, window_size=4)\n",
    "svd_reduced_co_occurrence = f.matrix_reduce(M_co_occurrence, method='svd', n_dim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 5)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_svd = np.stack([f.avg_svd_embeddings(ind, svd_reduced_co_occurrence, word2ind) for ind in reviews_ind])\n",
    "M_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1911.32207339  -42.3008621  -106.35712762  210.05471684 -132.18560823]\n",
      " [3295.92654462  -56.23929451 -170.39622825  528.90670811 -241.31622707]\n",
      " [6867.38013304  903.19521856 -400.92224674  805.06355756 -199.51484942]\n",
      " ...\n",
      " [3972.9144837    30.86035388 -292.65034272  950.86000508 -256.23313572]\n",
      " [1786.67156989 -840.48356118    8.95530309  -40.0365764  -613.58495126]\n",
      " [1798.51858078 -323.86781434   12.39257531 -192.91452964  260.19561892]]\n"
     ]
    }
   ],
   "source": [
    "print(M_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_pickle(M_svd, 'data/M_svd_100k.pickle')\n",
    "del M_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\klaud\\Anaconda3\\envs\\fastai-nlp\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:1077: ConvergenceWarning: Maximum number of iterations 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100000, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_reduced_co_occurrence = f.matrix_reduce(M_co_occurrence, method='nmf', n_dim=5)\n",
    "M_nmf = np.stack([f.avg_svd_embeddings(ind, nmf_reduced_co_occurrence, word2ind) for ind in reviews_ind])\n",
    "M_nmf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.60028164  2.57640671  2.69019925  7.05719044  2.88720161]\n",
      " [ 9.33532712  3.50661315  4.50025913 13.47148637  4.54616834]\n",
      " [12.983265   12.95530018 15.3185457  29.26370138  8.88202786]\n",
      " ...\n",
      " [ 9.86596451  3.9503121   4.99392973 18.75379105  5.03843315]\n",
      " [12.51094803  0.09438544  0.11250818  2.27895359  1.28957891]\n",
      " [ 4.79368268  2.69853506  2.86355823  2.46593873  8.70588731]]\n"
     ]
    }
   ],
   "source": [
    "print(M_nmf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_pickle(M_nmf, 'data/M_nmf_100k.pickle')\n",
    "del M_nmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert test string into SVD vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4686.7329675 , -783.00008166,   60.1869311 , -652.26470709,\n",
       "       1337.28247194])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.avg_svd_embeddings(review_ind_test, svd_reduced_co_occurrence, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.1192513 ,  7.95502596,  8.2426332 ,  4.97297233, 30.26983157])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.avg_svd_embeddings(review_ind_test, nmf_reduced_co_occurrence, word2ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=5,\n",
    "                     window=3,\n",
    "                     size=100,\n",
    "                     workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42808234, 50905110)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.build_vocab(reviews_tokens)\n",
    "w2v_model.train(reviews_tokens, total_examples=w2v_model.corpus_count, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_word2vec = np.stack([f.avg_w2v_embeddings(review, w2v_model) for review in reviews_tokens])\n",
    "M_word2vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.save_pickle(M_word2vec, 'data/M_word2vec_100k.pickle')\n",
    "del M_word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert test string into Word2Vec vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.6744937 , -1.213199  , -1.0238752 ,  0.03260673,  0.14862743,\n",
       "       -0.57608354, -0.97421134,  0.1169243 ,  0.48017493,  0.19547293,\n",
       "       -0.08849601,  0.4695232 , -0.8236923 , -0.02472959, -0.3976046 ,\n",
       "        1.0270191 ,  0.4643627 , -0.8565401 , -0.7912302 , -0.720211  ,\n",
       "       -0.58584607,  0.17372887,  0.4971673 , -0.4052841 , -1.0920483 ,\n",
       "        1.1958758 , -0.03497669, -0.14230634,  0.26223752,  1.1432084 ,\n",
       "       -0.42724353, -0.6125147 ,  0.7073124 , -0.2035555 , -0.06413691,\n",
       "       -0.07212701,  1.421565  ,  0.2852187 ,  0.12921596,  0.38929284,\n",
       "        0.27826518, -0.15381488,  0.51603484,  0.1501861 ,  0.0022732 ,\n",
       "       -1.0745842 ,  0.43908343, -0.5177313 , -0.066209  , -0.3127257 ,\n",
       "        0.34621722,  0.5059077 , -0.0310218 , -0.99942416, -0.68248177,\n",
       "       -0.47090307,  0.11102493, -0.21090198, -0.763354  ,  0.2564712 ,\n",
       "        0.44010442,  0.25490254,  0.1106451 , -0.4833456 , -0.08942149,\n",
       "        0.2028394 , -0.4401844 ,  0.10165071,  0.88994044,  0.9816888 ,\n",
       "       -0.84755915,  0.4416643 ,  0.64052   , -0.506839  ,  0.36738336,\n",
       "        0.31077558,  0.40993077,  0.7644635 ,  0.28560725,  0.13358071,\n",
       "       -0.34376678,  0.5002883 ,  0.02438222, -0.40687212, -0.3450397 ,\n",
       "        0.07463001,  0.49323636,  0.6793357 ,  0.3758401 ,  0.08358055,\n",
       "       -0.77123183, -0.6848518 , -0.29465303, -0.51238984, -1.0588214 ,\n",
       "        0.25055847,  0.4552378 , -0.3564204 ,  0.8358375 , -0.44737324],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.avg_w2v_embeddings(review_tokens_test, w2v_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-nlp",
   "language": "python",
   "name": "fastai-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
