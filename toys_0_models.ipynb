{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/M_bow.pickle', 'rb') as handle:\n",
    "    M_bow = pickle.load(handle)\n",
    "    \n",
    "with open('data/M_tfidf.pickle', 'rb') as handle:\n",
    "    M_tfidf = pickle.load(handle)\n",
    "    \n",
    "with open('data/M_svd.pickle', 'rb') as handle:\n",
    "    M_svd = pickle.load(handle)\n",
    "    \n",
    "with open('data/M_nmf.pickle', 'rb') as handle:\n",
    "    M_nmf = pickle.load(handle)\n",
    "    \n",
    "with open('data/M_word2vec.pickle', 'rb') as handle:\n",
    "    M_word2vec = pickle.load(handle)\n",
    "    \n",
    "with open('data/sentiment.pickle', 'rb') as handle:\n",
    "    y = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "M_svd_positive = scaler.fit_transform(M_svd)\n",
    "M_word2vec_positive = scaler.fit_transform(M_word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy:  0.914674872933972\n"
     ]
    }
   ],
   "source": [
    "baseline = sum(y)/len(y)\n",
    "print('Baseline accuracy: ', baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_names = ['BOW', 'TFIDF', 'SVD', 'NMF', 'Word2Vec']\n",
    "embeddings = [M_bow, M_tfidf, M_svd_positive, M_nmf, M_word2vec_positive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW \t 0.9452296163233482\n",
      "TFIDF \t 0.9213210800244281\n",
      "SVD \t 0.914674872933972\n",
      "NMF \t 0.5592889490943588\n",
      "Word2Vec \t 0.914674872933972\n"
     ]
    }
   ],
   "source": [
    "naive = MultinomialNB()\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    cv_results = cross_validate(naive, embeddings[i], y, cv=3, scoring=('accuracy', 'precision', 'recall'))\n",
    "    print(embeddings_names[i], '\\t', np.mean(cv_results['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = [M_bow, M_tfidf, M_svd, M_nmf, M_word2vec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW \t 0.9569507518789084\n",
      "TFIDF \t 0.9467272741295741\n",
      "SVD \t 0.8808934342148901\n",
      "NMF \t 0.914674872933972\n",
      "Word2Vec \t 0.9516185011221916\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(random_state=9)\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    cv_results = cross_validate(sgd, embeddings[i], y, cv=3, scoring=('accuracy', 'precision', 'recall'))\n",
    "    print(embeddings_names[i], '\\t', np.mean(cv_results['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW \t 0.9533033661541955\n",
      "TFIDF \t 0.9381332705102343\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log', penalty='elasticnet', random_state=9)\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    cv_results = cross_validate(sgd, embeddings[i], y, cv=3, scoring=('accuracy', 'precision', 'recall'))\n",
    "    print(embeddings_names[i], '\\t', np.mean(cv_results['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW \t 0.9469999789421054\n",
      "TFIDF \t 0.940000028797121\n",
      "SVD \t 0.9351000187001303\n",
      "NMF \t 0.9354999987101289\n",
      "Word2Vec \t 0.9435001388561172\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(max_iter=500, random_state=9)\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    cv_results = cross_validate(logreg, embeddings[i], y, cv=3, scoring=('accuracy', 'precision', 'recall'))\n",
    "    print(embeddings_names[i], '\\t', np.mean(cv_results['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW \t 0.9399997888211136\n",
      "TFIDF \t 0.9482002189421102\n",
      "SVD \t 0.9297001085831438\n",
      "NMF \t 0.9303004385621526\n",
      "Word2Vec \t 0.9432001688471187\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "model = XGBClassifier(random_state=9)\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    cv_results = cross_validate(model, embeddings[i], y, cv=3, scoring=('accuracy', 'precision', 'recall'))\n",
    "    print(embeddings_names[i], '\\t', np.mean(cv_results['test_accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-nlp",
   "language": "python",
   "name": "fastai-nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
